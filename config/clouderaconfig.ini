[CM]
cm.host = cmServer
cm.port = 7180
admin.name = admin
admin.password = admin
api.version = 16
cluster.name = BDE
db.type = postgresql
db.host = cmServer
db.port = 5432
db.user = root
db.passwd = s123456

activitymonitor.host = cmServer
#默认随机选择
hostmonitor.host =
#默认随机选择
servicemonitor.host =
#默认随机选择
eventmonitor.host =
#默认随机选择
alertpublisher.host =
#默认是/var/lib/cloudera-host-monitor
hostmonitor.storage.directory = dataBaseDir
#默认是/var/lib/cloudera-service-monitor
servicemonitor.storage.directory = dataBaseDir
#默认是/var/lib/cloudera-scm-eventserver
eventserver.index.directory = dataBaseDir

[CDH]
version = CDH5
fullVersion = 5.11.1
#所有部署了agent的机器列表
cluster.hosts = allHosts
cdh.parcel.version = 5.11.1-1.cdh5.11.1.p0.4

[ZOOKEEPER]
#部署Zookeeper服务的机器主机名列表，逗号分隔，配置为基数个，也可以不指定，脚本会根据集群规模自动选取
zookeeper.hosts =

#ZooKeeper将用来存其储数据库快照的磁盘位置,默认是/var/lib/zookeeper
zookeeper.dataDir =

#ZooKeeper Server 的 Java 堆栈大小（字节）,默认是536870912即512MB
zookeeper.server.java.heapsize =

[KAFKA]
#部署Kafka服务的机器主机名列表，逗号分隔，也可以不指定，默认添加所有机器
kafka.hosts =

#Kafka服务将用来存储数据的磁盘位置,多个目录用英文的逗号(,)隔开,默认是/var/local/kafka/data
kafka.log.dirs = dataDirs

#自动创建topic的默认副本数，默认是2
kafka.default.replication.factor =

#自动创建topic的默认分区数，默认是6
kafka.num.partitions =

#Kafka服务的最大Java堆栈大小（MB）,默认是512即512MB
kafka.broker_max_heap_size =

[HDFS]
#是否开启HA即NameNode的高可用，默认是true，如果不开启请设置为false
hdfs.ha.enable =

#NameService,当开启HA时需要配置,默认是sinorail
hdfs.nameservices =

#部署角色NameNode的机器,默认选择第一台
namenode.host =

#用于部署角色SecondaryNameNode或者当开启HA时部署角色StandByNameNode,默认选择第二台
secondary.host =

#部署角色DataNode的机器列表,默认是cluster.hosts中配置的所有机器
datanode.hosts =

#开启HA时部署角色JournalNode的机器列表,需要配置基数台(至少3台)机器,可以不配置,脚本中会有默认值
journalnode.hosts =

#NameNode数据目录,多个目录用英文的逗号(,)隔开,默认是/dfs/nnData
namenode.data.dirs =

#SecondaryNameNode数据目录,多个目录用英文的逗号(,)隔开,默认是/dfs/snnData
secondary.data.dirs =

#DataNode数据目录,多个目录用英文的逗号(,)隔开,默认是/dfs/dnData
datanode.data.dirs = dataDirs

#开启HA时部署角色JournalNode数据目录,默认是/dfs/jnnData
journalnode.data.dir =

[HBASE]
#HMaster地址列表,多个机器用英文的逗号(,)隔开,一般选择两台即可,也可以不指定,默认会选择两台
hbase.master.hosts =

#HRegionServer地址列表,默认是cluster.hosts中配置的所有机器
hbase.regionserver.hosts =

#HMaster的java堆內存大小（字节），默認是536870912即512M
hbase.master.java.heapsize =

#HRegionServer的java堆內存大小（字节），默認是2147483648即2G
hbase.regionserver.java.heapsize =

[YARN]
#是否开启HA即ResourceManager的高可用，默认是true，如果不开启请设置为false
yarn.ha.enable =

#ResourceManager地址,默认选择第一台
yarn.rm.host =

#备用ResourceManager地址,开启HA的时候需要配置,不能与yarn.rm.hosts配置一样,默认选择第二台
yarn.rm.bak.host =

#NodeManager地址列表,默认是cluster.hosts中配置的所有机器
yarn.nm.hosts =

#JobHistoryServer地址,默认会随机选择
yarn.jhs.host =

#Yarn服务的本地数据目录,多个目录用英文的逗号(,)隔开,默认是/yarnData
yarn.data.dirs = dataDirs

#单个NodeManager配置的可用内存大小,默认是10240即10G
yarn.nodemanager.resource.memory.mb =

[SPARK2]
#HistoryServer的地址,默认会随机选择
spark.historyserver.host =